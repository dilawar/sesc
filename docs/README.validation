
---- Comparing sesc with iacoma2  (R10K at 180Mhz)

                 Native   Simulated  Error SimulationTime*
    matrix         78ms        71ms   -10%    30s
    crafty        109ms       107ms    -2%    33s
    mcf           791ms       906ms    14%   113s
    mcf lgred.in 9120ms      9179ms    +1%
    mp3dec        643ms       568ms             139s
    lat_mem_rd   2405ms      2532ms    +5%      230s*2*
    lat_mem_rd   3461ms      3962ms                 *3*
    bw_mem        390ms       458ms              74s*4*
    bw_mem        620ms      1231ms                 *5*
---- Comparing sesc with iacoma1  (R4400 at 150Mhz)

                 Native   Simulated  Error SimulationTime*
    matrix        291ms       282ms    -4%       27s**
    crafty        265ms       272ms    +4%       23s
    mcf          2438ms      2387ms    -2%      177s
    mcf lgred.in22266ms  
    mp3dec       2341ms      1894ms   -22%      182s--------
    lat_mem_rd   4005ms      6806ms             279s*2*
    lat_mem_rd   not stable
    bw_mem       1166ms      1365ms                 *4*
    bw_mem       2156ms                             *5*

*Simulation Time is in a Athlon at 1.5Ghz

**r4400 has different FP latency see MIPSInstruction.cpp

*2*lat_mem_rd is a microbench from LMBench to calculate the latency of
the memory subsystem. The invocation is ./sesc -h0x800000 ../benchs/lat_mem_rd 1

*3*./sesc -h0x800000 ../benchs/lat_mem_rd 2

*4*bw_mem also belong to the LMBench suite. It was invoqued with
./sesc -h0xC00000 ../benchs/bw_mem 5242880 rdwr

*5* ./sesc -h0xC00000 ../benchs/bw_mem 5242880 fcp
 ---------------------------------------------------- 

Just to give an idea of the overhead of the simulator I calculated the
speed of MINT alone. The difference is benchmark dependent, sesc is
between 10 and 20 times slower than a strip down version of mint.

 ---------------------------------------------------- 

To visualize the results use the perl script called report.pl. A
typical output looks like:

# Bench : ./mtst1 ../src/smatrix native 128
# File  : sesc_smatrix.jLbUJU  :       Wed Dec 19 03:05:10 2001
Proc             Simulation Speed                Exe Time       Sim Time (180MHz)
   0        366.92 KHz       412.61 KIPS       42.68 secs       86.99 msec
Proc  Type         Total          RAS           BPred     BTB
   0  2bit       97.510% ( 95.00% of   0.00%)  99.79%  97.52%            # Branch
File  IPC         Cycles    Busy      Control     Window    Data  Struct  Memory
   0  1.12      15659022  28.12%   0.06%   0.84%  45.63%   3.57%   2.93%  18.85% # Trad CPU


The 1st line "# Bench... " specified the benchmark exectuted with the parameters

The 2nd line shows the configuration file and the date of the file

The 3rd and 4th line show the simulation performance:

 Exe Time is the time that it took to run the simulation.
 KIPS stands for thousands of instructions simulated per second.
 Sim Time is the simulated execution time. 1Ghz by default, but -f=<freq> can change it.

The 4th and 6th line are statistics about the branch predictor.
 
 Type is the type of predictor selected (in sesc_smatrix.jLbUJU you have the details)
 Total is the prediction for all kind of branches. (not only taken/noTaken but also address)
 RAS has two fields. The first one is the prediction rate (95.00%), the second says the coverage (0%)
 BPred is the prediction accuracy for taken/noTaken
 BTB is the prediction accuracy for the branches that were predicted taken.

The 7th and 8th line show the performance of the processor.

 IPC if you don't know that go read the Hennessy and Patterson first.
 Cycles idem
 Busy percentage of time busy. (IPC/maxIssue)
 Control has two fields. The first is the effect of mispredictions, the second the effect
  of the constraints in the issue engine (one branch per cycle and maxBranches)
 Window when the pipeline is stalled because the window is full, the time is charged to the window.
  It may be because the window is too small or because Data+Struct+Memory are the bottlenecks.
  If you increase the window, but the percentage remains simular, this time should be
  transfered to Data+Struct+Memory.
 Data  Percentage of time due to data dependences
 Struct due to constrains in the resources
 Memory: Percentage of time due to memory time (Difference with a perfect L1 cache memory backend)



